{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test environment, Create a folder to store result",
   "id": "7991e0b846998375"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T20:54:14.976041Z",
     "start_time": "2025-08-29T20:54:14.971413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, pathlib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "pathlib.Path(\"Out\").mkdir(exist_ok=True)\n",
    "print(\"Out/ ready.\")\n",
    "\n",
    "load_dotenv()\n",
    "print(\"Env loaded. API_KEY present? \", bool(os.getenv(\"API_KEY\")))\n",
    "print(\"Kernel OK.\")"
   ],
   "id": "72ae3f0dce2be70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out/ ready.\n",
      "Env loaded. API_KEY present?  True\n",
      "Kernel OK.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test API Key and Search Engine ID",
   "id": "19e5f17c64a7a99b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T20:54:15.936630Z",
     "start_time": "2025-08-29T20:54:15.934860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "CX_ID = os.getenv(\"CX_ID\")\n",
    "GOOGLE_API = 'https://www.googleapis.com/customsearch/v1'\n",
    "assert API_KEY and CX_ID, \"Set API_KEY and CX_ID in your .env file\"\n",
    "print(\"OK, keys loaded.\")"
   ],
   "id": "bc9be4d460fbd877",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK, keys loaded.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup Queries and Pages",
   "id": "576e866730399572"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T20:54:17.058360Z",
     "start_time": "2025-08-29T20:54:17.053114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "\n",
    "PAGES = os.getenv(\"PAGES\")\n",
    "FOLLOWER_MIN=os.getenv(\"FOLLOWER_MIN\")\n",
    "SITES = pathlib.Path(\"queries\") / \"sites.json\"\n",
    "CITIES = pathlib.Path(\"queries\") / \"cities.json\"\n",
    "VIEWS = pathlib.Path(\"queries\") / \"views.json\"\n",
    "PATTERNS = pathlib.Path(\"queries\") / \"patterns.json\"\n",
    "KEYWORDS = pathlib.Path(\"queries\") / \"keywords.json\"\n",
    "\n",
    "def create_queries() -> dict[str, list[str]]:\n",
    "    with open(SITES) as sites_file:\n",
    "        sites = json.load(sites_file)\n",
    "    with open(CITIES) as cities_file:\n",
    "        cities = json.load(cities_file)\n",
    "    with open(KEYWORDS) as keywords_file:\n",
    "        keywords = json.load(keywords_file)\n",
    "\n",
    "    q = dict()\n",
    "    for site in sites[\"social_media\"]:\n",
    "        # modify this part to get different filter combos\n",
    "        q[site] = [f\"{site} {keyword} {city}\" for keyword in keywords[\"nail\"] for city in cities[\"top_major_cities\"]]\n",
    "\n",
    "    return q\n",
    "\n",
    "QUERY = create_queries()"
   ],
   "id": "bfa12c98b77c61e6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Parse url and gather data with patterns and queries",
   "id": "b7414cf3f072adb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T20:54:18.407709Z",
     "start_time": "2025-08-29T20:54:18.404806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def customized_search(query: str, start: int = 1):\n",
    "    r = requests.get(GOOGLE_API, params={\n",
    "        \"key\": API_KEY,\n",
    "        \"cx\": CX_ID,\n",
    "        \"q\": query,\n",
    "        \"start\": start\n",
    "    }, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def gather_raw_data(query: dict[str, list[str]]) -> dict[str, list[str]]:\n",
    "    raw_data = dict()\n",
    "    for site, fil in query.items():\n",
    "        raw_data[site] = customized_search(fil).get(\"items\", [])\n",
    "    return raw_data"
   ],
   "id": "3227e4c7503447e5",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T20:54:19.090239Z",
     "start_time": "2025-08-29T20:54:19.082762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_ig_url(url: str) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Given a URL, return its username.\n",
    "    :param url:\n",
    "    :return: account web address\n",
    "    \"\"\"\n",
    "    p = urlparse(url)\n",
    "    url_segments = p.path.split(\"/\")\n",
    "    if url_segments[0].lower() not in {\"p\", \"reels\", \"stories\", \"explore\", \"tv\", \"channels\", \"direct\"}:\n",
    "        return url, \"a\"\n",
    "    elif url_segments[0].lower() == \"p\":\n",
    "        return url, \"p\"\n",
    "    return \"none\", \"none\"\n",
    "\n",
    "\n",
    "def parse_nums(m):\n",
    "    if not m:\n",
    "        return 0\n",
    "\n",
    "    num_str, suffix = m.groups()\n",
    "    num = float(num_str.replace(',', ''))\n",
    "\n",
    "    mult = {\n",
    "        None: 1,\n",
    "        '': 1,\n",
    "        'K': 1_000,\n",
    "        'M': 1_000_000,\n",
    "        'B': 1_000_000_000\n",
    "    }\n",
    "    return int(num * mult.get(suffix.upper() if suffix else '', 1))\n",
    "\n",
    "\n",
    "def parse_ig_followers(raw):\n",
    "    pattern = '(\\\\d[\\\\d,.]*)\\\\s*(K|M|B)?\\\\s+followers'\n",
    "    m = re.search(pattern, raw, re.I)\n",
    "    return parse_nums(m)\n",
    "\n",
    "\n",
    "def parse_ig_posts(raw):\n",
    "    pattern = '(\\\\d[\\\\d,.]*)\\\\s*(K|M|B)?\\\\s+posts'\n",
    "    m = re.search(pattern, raw, re.I)\n",
    "    return parse_nums(m)\n",
    "\n",
    "def parse_ig_following(raw):\n",
    "    pattern = '(\\\\d[\\\\d,.]*)\\\\s*(K|M|B)?\\\\s+following'\n",
    "    m = re.search(pattern, raw, re.I)\n",
    "    return parse_nums(m)\n",
    "\n",
    "def trim_after_posts(raw: str) -> str:\n",
    "    if not raw:\n",
    "        return \"\"\n",
    "\n",
    "    # Normalize common invisible spaces\n",
    "    s = raw.replace(\"\\xa0\", \" \")\n",
    "\n",
    "    # Find 'posts' (or 'post') as a whole word\n",
    "    m = re.search(r'\\bposts?\\b', s, flags=re.IGNORECASE)\n",
    "    if not m:\n",
    "        return s.strip()\n",
    "\n",
    "    # Everything after the word 'posts'\n",
    "    tail = s[m.end():]\n",
    "\n",
    "    # Strip leading punctuation/delimiters often seen after 'Posts'\n",
    "    # (space, dots, hyphen, en/em dash, colon, bullets, pipes)\n",
    "    tail = re.sub(r'^[\\s\\.\\-–—:•·|]+', '', tail)\n",
    "\n",
    "    return tail.strip()\n",
    "\n",
    "def clean_instagram_title(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Strip trailing '• Instagram …' (any suffix starting with a separator + 'Instagram')\n",
    "    from Google CSE titles, even if truncated with … or '...'.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        return \"\"\n",
    "\n",
    "    t = title.replace(\"\\xa0\", \" \").strip()\n",
    "    t = re.sub(r\"\\s+\", \" \", t)  # normalize whitespace\n",
    "\n",
    "    # Remove: [separator] Instagram ... [to end]\n",
    "    # separators seen: • · - – — | (&bull; sometimes appears)\n",
    "    t = re.sub(\n",
    "        r'\\s*(?:[•·\\-\\–\\—|]|&bull;)\\s*Instagram\\b.*$',\n",
    "        '',\n",
    "        t,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Also handle rare '(Instagram)' suffixes\n",
    "    t = re.sub(r'\\s*\\(\\s*Instagram\\s*\\)\\s*$', '', t, flags=re.IGNORECASE)\n",
    "\n",
    "    # Trim dangling punctuation/spaces\n",
    "    t = t.strip(' -–—|·•').strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "FOLLOWER_THRESHOLD = 2000\n",
    "\n",
    "\n",
    "def parse_and_filter_ig_data(raw_data):\n",
    "    result = dict()\n",
    "\n",
    "    for value in raw_data['instagram.com']:\n",
    "        d = dict()\n",
    "        raw_title = clean_instagram_title(value['title'])\n",
    "\n",
    "        raw_url = value['link']\n",
    "        raw_snippet = value['snippet']\n",
    "\n",
    "        parsed_url = parse_ig_url(raw_url)\n",
    "        if parsed_url[1] == 'p':\n",
    "            # result is a post, temporarily skip this result\n",
    "            continue\n",
    "        elif parsed_url[1] == 'a':\n",
    "            # result is an account\n",
    "            follower = parse_ig_followers(raw_snippet)\n",
    "            if follower < FOLLOWER_THRESHOLD:\n",
    "                # we don't care followers < 2k accounts\n",
    "                continue\n",
    "            else:\n",
    "                following = parse_ig_following(raw_snippet)\n",
    "                post = parse_ig_posts(raw_snippet)\n",
    "                description = trim_after_posts(raw_snippet)\n",
    "        else:\n",
    "            # dont handle this case for now\n",
    "            continue\n",
    "        d['type'] = 'a'\n",
    "        d['url'] = parsed_url[0]\n",
    "        d['follower'] = follower\n",
    "        d['following'] = following\n",
    "        d['post'] = post\n",
    "        d['description'] = description\n",
    "        result[raw_title] = d\n",
    "    return result"
   ],
   "id": "9ed5d1f75460859e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T20:54:19.741950Z",
     "start_time": "2025-08-29T20:54:19.739594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# df = pd.DataFrame.from_dict(data, orient=\"index\")"
   ],
   "id": "e1bc11abe9a6f67b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T20:54:20.313494Z",
     "start_time": "2025-08-29T20:54:20.309678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "def save_profiles_to_csv(data: dict, path: str = \"instagram_profiles.csv\"):\n",
    "    \"\"\"\n",
    "    Save your {title: {...fields...}} dict to a CSV.\n",
    "    \"\"\"\n",
    "    # Desired column order (others will be appended if present)\n",
    "    base_fields = [\"title\", \"type\", \"url\", \"follower\", \"following\", \"post\", \"description\"]\n",
    "\n",
    "    # Build rows and collect any extra keys that appear\n",
    "    rows, extra_keys = [], set()\n",
    "    for title, info in data.items():\n",
    "        row = {\"title\": title}\n",
    "        row.update(info or {})\n",
    "        rows.append(row)\n",
    "        extra_keys.update(k for k in row.keys() if k not in base_fields)\n",
    "\n",
    "    # Final field order\n",
    "    fieldnames = base_fields + sorted(extra_keys)\n",
    "\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        w.writeheader()\n",
    "        for r in rows:\n",
    "            # ensure all fields exist (avoid KeyError)\n",
    "            for k in fieldnames:\n",
    "                r.setdefault(k, \"\")\n",
    "            w.writerow(r)\n",
    "\n",
    "# Example:\n",
    "# save_profiles_to_csv(data, \"profiles.csv\")"
   ],
   "id": "44da8999714fdd67",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(\"Hello World!\")\n",
   "id": "fbc121e30a2defb3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
